% !TEX program = pdflatex
\documentclass[11pt]{article}
\usepackage{palatino}
\usepackage{fullpage}
\usepackage{listings}
\usepackage{url}
%\usepackage{chronology}
% Shell command markup
\newcommand{\shellcmd}[1]{\texttt{\footnotesize #1}}

% Rename this file to cis452-weekNN.tex
% To produce a PDF output, type the following on EOS
%
%  pdflatex cis452-weekNN.tex
%
\title{CIS452 Week-09 Notes}
\author{Winter 2016}
\date{March 14 - March 18, 2016}
\begin{document}
\maketitle

\noindent
\textbf{Scribes:} \textit{Hayden Miedema} and \textit{Sage Heiss}

\section*{OS as a resource manager}
\begin{itemize}
	\item Chapters 3-6
	\begin{itemize}
		\item As a process manager, the OS creates an illusion that..
		\item A user “owns” the CPU to his/herself
		\item  A process is running on the CPU at all times
		\item Programmers can ignore the fact at runtime, their program may not be running on the CPU all the time	
	\end{itemize}
\end{itemize}

\section*{OS: The memory illusionist - Creates illusion of...}
\begin{itemize}
	\item A process owns the entire RAM to itself
	\item A process resides in RAM all the time
	\item The code (generated by the compiler) starts at address “zero”
	\item Code and data are contiguous in memory
	\item A process has access to (tera|peta|exa)bytes* of memory space

\end{itemize}

\clearpage
\section*{OS: The memory facts}
	\begin{itemize}
		\item Your process has to share the RAM with many other processes
			\begin{itemize}
				\item OS task: Memory Protection and sharing
			\end{itemize}
		
		\item At times a process may be swapped out of RAM
				\begin{itemize}
					\item OS task: Process Relocation
				\end{itemize}
		\end{itemize}

		\item The code may be loaded (and reloaded) at any memory address
				\begin{itemize}
					\item OS task: Load a process to a free memory region
				\end{itemize}
		\item Code and data may be split into segments/pages
		\item The actual amount of space accessible to a process is the RAM size
		\end{itemize}

\section*{Memory sharing and Protection}
	\begin{itemize}
		\item Several processes may concurrently reside in RAM
			\begin{itemize}
				\item Each process has diff. size
				\item Each process is placed at diff. memory location
			\end{itemize}
		\item Sharing: divide the RAM into regions, place a process in one region
		\item Protection: prohibit one process to peek into another’s region
			\begin{itemize}
				\item Protection violation must be (initially) detected/reported by the memory hardware and (later) handled by the OS
			\end{itemize}
		\item Two special Registers:
			\begin{itemize}
				\item Base register: the starting address of a region
				\item Limit register: size of the region
				\item These two registers are saved/restored during a context-switch
			\end{itemize}
	\end{itemize}
\begin{itemize}
	\item Select Hightest Priority Task first
	\item Always preemptive - Let High priority tasks interrupt low priority
	\item Without aging or some other algorithm, low priority processes can starve
\end{itemize}

\section*{Address Binding}
\begin{itemize}
	\item A user program refers to data/variables/functions using symbolic names
	\item Compile-Time Address Binding
	\begin{itemize}
		\item Compiler and linker bind each symbolic name to a memory address
	\end{itemize}
	\item Load-Time Address Binding
	\begin{itemize}
		\item The OS loads the binary executable to an open space in RAM
	\end{itemize}
	\item Run-Time Address Binding
	\begin{itemize}
		\item A process may be relocated at a different address
		\item A process may call functions shared among several process (the actual location of these functions must be resolved at runtime)
		\item Windows (.DLL) and Unix Shared Objects (.so)
			(see full diagram in Google Slides)
	\end{itemize}
	\item Logical/Virtual Address: generated by CPU
	\item Physical Address: address issued to memory
\end{itemize}

\section*{Dynamic Loading/Linking}
	\begin{itemize}
	\item Problem: Large Process size, limited RAM size
	\item Dynamic Loading (“Overlay”)
	\begin{itemize}
			\item Routines needed by a process are loaded on-demand
			\item No special OS support needed, the user process is responsible for loading its overlay
	\end{itemize}
	\item Dynamic Linking & Shared Libraries
	\begin{itemize}
			\item Opposite variant of static linking
			\item At linking time, the linker includes only a stub about the target functions in the shared library
			\item The actual linking to the shared libraries are postponed until runtime
			\item When a new version of shared libraries becomes available, a user program will invoke the newer version without recompilation/relinking 
	\end{itemize}
	\item Similar to multi-feedback, long period processes get low priority and vice versa.
	\end{itemize}

\section*{Swapping}
	\begin{itemize}
		\item A process must be resident in RAM to run 
		\item When more memory is needed, the Medium Term Scheduler may swap out processes
		\item Processes in the ready queue are good candidates for swapping out
		\item When a process is (being) swapped out
		\begin{itemize}
			\item	The entire current process image is dumped to swap space
			\item All memory areas owned by the process are released
		\end{itemize}
		\item Swapping allows the system to host several processes whose total memory requirement may exceed the physical RAM size
		\item Swap space/Swap disk: a designated disk used for the binary process image of swapped out processes
	\end{itemize}

\section*{Swapping-Related Issues}
	\begin{itemize}
		\item OS maintains two ready queues
		\begin{itemize}
			\item	Processes which are ready and resident in RAM
			\item Processes which are ready but swapped out
		\end{itemize}
		\item When a process is swapped (back) in, it may resume execution at a different physical 
		\item A process to be swapped out should be completely IDLE
			\begin{itemize}
				\item No pending I/O (because pending I/O requires target buffer to be resident in RAM)
			\end{itemize}
			\item Swapping is very SLOOOOW (may take seconds to complete)
				\begin{itemize}
					\item HD transfer rate is about 50 MB/sec
					\item SSD transfer rate is about 750 MB/sec
				\end{itemize}
			\item Swapping is not beneficial in terms of speed, but swapping is very key/important to allow the system to take more processors, thus more processes in the system and greater CPU utilization.
	\end{itemize}

\section*{Contiguous Memory Allocation}
	\begin{itemize}
		\item Goal: shared RAM by many processes
		\item Memory Partitions
			\begin{itemize}
				\item One partition can only hold one process
			\end{itemize}
		\item Fixed-size vs. Variable size partitions
			\begin{itemize}
				\item Fixed: location and size of each partition are predefined by the OS
					\begin{itemize}
						\item Size of each partition will stay the same throughout that boot cycle
					\end{itemize}
				\item Variable: location and size of each partition are determined on-demand, per partition request.
			\end{itemize}

\section*{Fixed-Sized Partitions}
	\begin{itemize}
		\item RAM is divided into N partitions (of different sizes, but fixed)
		\item Only max N processes can resided in RAM at any time
			\begin{itemize} 
				\item One partition = one process
				\item Fixed multiprogramming level
			\end{itemize}
		\item When a process is loaded to RAM, the system selects a free partition big enough to fit the process
		\item (Internal) Fragmentation: unused portion (wasted space) of a partition 
			\begin{itemize}
				\item Scheduling Issues? Ready Queue(s)?
					\begin{itemize}
						\item N ready queues, since each partition is a different size
					\end{itemize}
			\end{itemize}
	\end{itemize}

\section*{Variable-Sized Partitions}
	\begin{itemize}
		\item Partitions are created on-demand as processes are loaded
				\begin{itemize}
					\item Partition size = size of the process just loaded
					\item No internal fragmentation
				\end{itemize}
		\item But, when a process terminates, it creates a hole (free partition)
		\item The OS maintains…
				\begin{itemize}
					\item A list of allocated partitions
					\item A list of holes (free partitions) link the “holes” themselves into a linked list
				\end{itemize}
		\item When a process is loaded, the OS looks for a hole big enough for the process
				\begin{itemize}
					\item Unused portion of the hole becomes a smaller hole
				\end{itemize}
	\end{itemize}

\section*{Algorithms}
\begin{itemize}
	\item First Fit: scan from head and put in first found partition
	\item Next Fit: scan from last fit point and scan until the first fit appears
	\item Best Fit: scan entire RAM and give minimum leftover partition
	\item Worst Fit: scan entire RAM and give maximum leftover partition
\end{itemize}		

%Friday notes here
\section*{Hex Arithmetic}
	\begin{itemize}
		\item See table on handout or Google Slides
	\end{itemize}

\section*{Segmentation and Segmentation Hardware}
	\begin{itemize}
		\item Base and Limit Register pairs get replaced with a segment table
		\item Since each is contiguous (stack, heap, etc.) we can keep them in the table sequentially
		\item More significant bits are used for the segment ID (seg #) 
		\item Less significant bits are then used for the offset
		\item These can both be used to find the base address and size of that given segment
		\item If no errors, the hardware will add the two numbers (size and base addr.) to give the final physical address
		\item Improvements over Variable-sized Segmentation:
			\begin{itemize}
				\item Less wasted space
			\end{itemize}
	\end{itemize}

\section*{Paging}
	\begin{itemize}
		\item Partition RAM into equal fixed-size blocks (frames) and split processes into blcoks of the same size
		\item Logical pages ust be mapped
		\item Only the current page(s) must be visible, all other pages can be inaccessible
		\item The base address of a page table is kept in Page Table Base Register (PTBR)
		\item pages (of a process) can be loaded to RAM on-demand
		\item Page tables have the same structure as the segmentation table, but we do not need to keep the size since they are all the same
	\end{itemize}
\end{itemize}

\section*{Paging vs. Segmentation}
	\begin{itemize}
		\item design of a page table is much simpler than a segment table
		\item In segmentation, one segment (for instance code segment) is mapped contiguously
		\item Obviously, page # is now used over segment #
	\end{itemize}
\end{document}
